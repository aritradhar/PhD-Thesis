\section{Problem Statement}
\label{pie:sec:problemStatement}

Modern platforms are composed of complex heterogeneous \sphw, from simple IO devices such as keyboard, mouse to complex devices such as a GPU for machine learning or fast NIC to process huge amount of network traffic and execute cryptographic operations on them. All these components are connected to the CPU over buses (e.g., PCI, USB, etc.). Many modern applications that leverage trusted paths are critically dependent on such \sphw, and often they handle sensitive data, e.g., patient records for machine learning. Thus, these \sphw{}s' authenticity and integrity are critical, and the data they handle must remain confidential. We list three such trusted path applications in the following ranging from the simple IO operation to complex accelerator that provides their own execution environment:


\myparagraph{Application 1: Trusted path for IO devices} A user uses her IO devices (keyboard, mouse, display, etc.) to interact with an online banking application running on her device. The user wants to verify that the banking application is exclusively accessing her IO devices. In this case, the user wants to harden her system against a potentially compromised software stack.

\myparagraph{Application 2: Trusted path to sensor readings}
Safety-critical industrial and medical devices rely on measurements of critical sensors. E.g., a pressure sensor provides data to the industrial controller, who decides when to open a safety valve.


\myparagraph{Application 3: Trusted path to isolated execution on accelerators} 
Many science fields require a vast amount of computation power, which a general-purpose processor can no longer provide. In recent times, specialized hardware which is very efficient for one specific problem is used in the form of accelerators, e.g., machine learning accelerators in the cloud. Such applications often handle sensitive data such as patient records and require isolation from the OS and other applications running on the same GPU. 

In all of the above applications that handle sensitive data and use a \sphw device can be deployed securely with one of the following three existing approaches: 1) designing a fully dedicated system, or 2) renting a dedicated virtual machine and placing trust in the hypervisor, or 3) relying on the OS. None of these approaches to be satisfactory due to lack of generality, cost, and the need to trust codebases with millions of lines of code~\cite{torvalds2020linux,barham2003xen}. Existing TEEs such as Intel SGX, RISC-V Keystone, ARM TrustZone, etc., provide security guarantees only to the applications running on the CPU cores leaving \sphw unprotected. Moreover, SGX and Keystone enclaves rely on the untrusted OS to communicate with \sphw. On the other hand, ARM TrustZone provides isolated communication between the enclaves and components such as a touchscreen, fingerprint sensor but requires trusting the entire secure OS, including device drivers not used by the enclave. 


\subsection{Attacker Model}
\label{pie:sec:problemStatement:attackerModel}

The attacker model is tightly coupled with the type of \sphw. We separate the \sphw into two main classes due to their distinct effect on the attacker model: 
%\sphw that explicitly interact with their physical environment and those that do not. Intuitively, sensors interact with their environment by taking measurements. Accelerators, however, do not explicitly interact with the real world. The \sphw classes and their respective attacker models are described in the following:

\begin{enumerate}
\item \emph{\Sphw with physical interaction:}
\Sphw that interact with their environment range from input-only, such as input peripherals (e.g., mouse, keyboard) and sensors (e.g., temperature sensor) to output-only devices (e.g., a monitor) and combined IO devices (e.g., touchscreen). For any such device, a local physical adversary can manipulate the environment and thus the input (and potentially the output). E.g., a physical adversary can point a laser at a light sensor, thus changing the sensor's reading but not the room's overall light intensity. Hence, any \sphw that interacts with its physical environment cannot tolerate a physical adversary.

\item \emph{\Sphw without physical interaction:}
There are \sphw units that do not explicitly interact with their environment. They draw power and produce heat, but their input and output are not related to the environment. GPUs and other accelerators are the prime examples of this class of \sphw, for whom a local physical adversary can be tolerated. 
\end{enumerate}

For the most part of this chapter, we assume a remote attacker who remotely controls the entire software stack - the OS and hypervisor. While the remote attacker model is a weaker assumption compared to the local physical one considered in the existing TEEs, the former covers a wide class of \sphw (e.g., \sphw with physical interaction) that cannot tolerate physical attackers. Hence, the attacker cannot access the platform of the \sphw physically or hot-swap a device. Note that the untrusted OS is still in charge of managing \sphw devices and thus is able to remap the devices or send a reset or power-off signal. In addition, an adversary may launch DMA attacks using rogue peripherals.

Later in this chapter, in~\Cref{pie:sec:localAttacker}, we also discuss how we can make some modifications to our proposal to adopt with a local physical attacker. 

In both of the cases (remote and local attacker), we assume that the CPU firmware is trusted. Similar to existing TEE proposals, side-channel attacks remain out of scope~\cite{costan2016intel} in our adversary model. However, we will discuss the implications of our proposal on existing side-channel attacks and defenses in \Cref{sec:securityAnalysis}. Finally, we consider denial-of-service attacks to be out of scope in this paper. 



\subsection{Challenges}
\label{pue:sec:problemStatement:challenges}

As mentioned above, several approaches could be pursued to integrate \sphw into a TEE. Among them, we investigate approaches that reuse components of existing systems as much as possible, both in terms of software and in terms of hardware.  
This approach leaves the OS in a supervisor role, liaising between the isolated environments and \sphw, similar to a memory in traditional TEEs (refer to  Section~\ref{ch:background:SGX}). But, this decision leaves leeway for privileged adversaries to break the system's isolation. We, therefore, need to consider both existing threats to traditional TEEs and emerging threats due to the nature of a reconfigurable hardware TCB. 
We analyze these in more detail in the next three paragraphs.


\myparagraph{Secure communication}
Traditionally, the OS or the hypervisor act as the bridge between applications and \sphw. They are responsible for set-up these communication links properly and can not only observe the data exchanged between different components but also tamper with it. As they are not trusted in our attacker model, we need to ensure that each component establishes a secure link with the other. This is not trivial, as the OS is untrusted and may not cooperate. 
Finally, the fact that several accelerators may need to support a form of multi-tenant isolation (e.g., multiple tasks on a GPU) requires careful consideration, as sensitive data within an isolated environment in \name should remain confidential irrespective of what else is running on the system.



\myparagraph{Remote Attestation}
Remote attestation is a key part of any TEE. However, with multiple \sphw devices and enclaves on the CPU making up a distributed enclave, the straightforward approach to just individually attest to every component is vulnerable to time-of-check-time-of-use attacks. Several attestations (one for each component of the TEE) must be linked with a guarantee that nothing has changed in the components already attested since the last attestation. Without this guarantee, an attacker could tamper with the configuration of already attested enclaves and thus tricking the remote verifier.

\myparagraph{Runtime attacks}
Remapping attacks are also relevant during runtime, as the OS still manages the memory. Well-timed disconnects or memory remappings could result in leakage of confidential data, e.g., if an attacker remaps a \sphw device and replaces it with a malicious device, the CPU enclave should not share sensitive data with the new device. 

