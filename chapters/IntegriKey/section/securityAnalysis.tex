\section{Security Analysis}
\label{sec:securityAnalysis_IK}

In this section, we provide an informal security analysis of our system. The goal of the adversary is violate the \emph{integrity} of web input. Examples include a misconfiguration of a safety-critical device or a false payment against the intention of the user. 


%\subsection{Privacy of User Input} 
%
%Note that the \device opens two channels: $TLS_1$ and $TLS_2$ through the host where the data sent via the $TLS_2$ channel serves as the second factor for the integrity of the input data. One may think that \name may pose a privacy threat to the users as all of the input data from the user may end up to the servers that implement the \name server-side component. We cam argue that \name does not open up additional privacy leakage due to following reasoning:
%\begin{enumerate}
%\item As the \device uses \webusb as the communication channel through the host's browser, the implementation of the \webusb restricts only one website (known as the \emph{landing page}) to bind with the \usb device~\cite{webuseb_google}. This ensures that when the user switches the browser tab or application, the keystrokes from that application will not be forwarded to the \device unless the user reinitializes the device manually.
%\item The \device uses a white-list to communicate with the remote server. This way, the \device only establishes a secure channel when the user opens up the specific websites in the browser. 
%\item \name does not guarantee the privacy of the input, only provides the integrity and the authenticity of the same. As we consider the host to be fully compromised, the host can always cache all the user provided input and broadcast to all the servers. \name ensures that the inputs that are received at the remote server side are irrigated legitimately from the user.
%\item In safety-critical applications, we can safely assume that the user uses a dedicated host system along with the \device to program a remote end-system. In such cased we can rule out other application scenario. In the case, user users her general-purpose hosts system to peogram the remote safety-critical device,  
%\end{enumerate}
%
%Given our adversary model, the adversary has the following options to mount attacks. First, the adversary can modify the \emph{user interface} that is shown to the user. Second, the adversary can control the communication channel \emph{from the host to the server} ($TLS_1$). Given our system design, the adversary cannot inject any messages into the channel from \device to the server ($TLS_2$), i.e., all user keyboard events received by the server were generated by the user. 



\subsection{Arbitrary Modifications} 

The simplest adversarial strategy is to manipulate only the application payload that is sent to the server. The adversary can, e.g., change one input value provided by the user to another arbitrary value in the HTTP response. Such attacks are detected by the server because the configuration data received over $TLS_1$ does not match the traces received over $TLS_2$.


\subsection{Swapping Attacks}
%\label{sec:analysis:swapping}

A more sophisticated adversarial strategy is to manipulate both the application payload and the user interface at the same time. More specifically, the adversary can change the names and the order of the user input fields and modify any instructions that are part of the user interface, such as the labeling instructions. Figure~\ref{fig:swapExample} shows one such example of the attack where the field names `\texttt{Relay temp 1}' and `\texttt{Relay temp 2}' are swapped.


The goal of a swapping attack is that the server interprets the received input values with different semantics than the user intended. Assuming that the user interface contains interchangeable fields, the adversary can construct an HTTP response where all input values are listed in the correct order and their values match to the input events. Two variants of such attacks are possible. 

\myparagraph{Manipulated field names or instructions} 
In the first variant, the adversary manipulates \emph{either} the field names \emph{or} the instructions. In such a case, the user interface that is shown to the user has an \emph{inconsistency}, because the input field names and the labeling instructions do not correspond to each other. The user may react in different ways that we enumerate below:
%\vspace{-5pt}
\begin{itemize}
    \item \emph{Case 1: Abort.} The user may notice the inconsistency in the UI and abort the process. \label{detect}
    
    \item \emph{Case 2: Correct labeling.} The user may perform the labeling correctly. That is, he may prefix each entered input value with the matching label. The target device is configured correctly, despite the user interface manipulation.\label{notdetect}
    
%    \item \textbf{Case 3: Correct labeling (UI).} The user may label each input based on the manipulated UI and against the labeling instructions. The server will detect the user interface manipulation, because the user inputs are received in a wrong order, and abort the configuration process. \todo{Hmmm... confusing... merge 2 and 3?}\label{corrLable}
    
    \item \emph{Case 3: Incomplete labeling.} The user may fail to complete the required labels. The server will abort the process. 
    
    \item \emph{Case 4: Incorrect labeling.} Finally, the user may perform the labeling incorrectly. That is, he may associate one of the asked input values with incorrect (and swappable) label prefix. The server cannot detect this case and the target device will be misconfigured. \label{kaboom}
\end{itemize}
%\vspace{-8pt}

In Section~\ref{sec:results:userStudy} we report results of a small-scale user study that provides preliminary evidence on how common these cases are, and especially how many people would fall for the attack (\emph{Case 4}).


\myparagraph{Manipulated field names and instructions} 
In the second variant, the adversary manipulates \emph{both} the field names and the labeling instructions. In this variant, there are two possible cases. First, the labeling instructions do not correspond to the UI field order, in which case the effect is the same as above. Second, the modified labeling instructions correspond to the modified UI, i.e., the matching field names and labeling instructions are both modified the same way. In this case, the labeling instruction reordering essentially nullifies the effect of UI field name reordering and the UI is consistent again (no risk of misconfiguration).


We conclude that any manipulation of (\emph{i}) UI field names, (\emph{ii}) values in the application payload, (\emph{iii}) labeling instructions in the UI, or (\emph{iv}) the combination of thereof cannot violate input integrity unless there is a visible indication of it (i.e., inconsistency) in the user interface. This is the \emph{Case 4} above which we evaluate with a small user study.

%\myparagraph{Corrupted labels} Compromised host can manipulate any content shown on the screen. However, \name protects against such manipulation, as the user-provided labels will not match the labels expected by the server. The results in the server rejecting the input altogether. One example is illustrated in Figure~\ref{fig:payload} where the server expects \texttt{rel1:r1} from both the \device and the browser. The host may manipulate the labeling instruction and trick the user into providing the wrong label, but the server will reject wrong labels.  

%\myparagraph{Manipulated labels and instructions} The adversary can also modify both the labels and  One such example is a webpage that contains two fields: \texttt{relay 1} and \texttt{relay 2}. Assume the correct labelling is \texttt{rel1} and \texttt{rel2} respectively. The attacker can change the instruction of labelling to \texttt{rel2} and \texttt{rel1}. We can argue that such modification will create suspicion to the users. In the user study, we saw that majority of the users detect the discrepancy with the text field label names and the instruction corresponding to that text fields. 


\subsection{Privacy Considerations} 
\label{sec:privacy}

In our solution, the trusted \device device intercepts the user's keyboard input events and sends a trace of them to the server for matching. As \emph{any} interception-based solution has obvious privacy concerns, in this section we explain why the typical and recommended usage of our solution does not violate user's privacy.

%Note that the \device opens two channels: $TLS_1$ and $TLS_2$ through the host where the data sent via the $TLS_2$ channel serves as the second factor for the integrity of the input data. One may think that \name may pose a privacy threat to the users as all of the input data from the user may end up to the servers that implement the \name server-side component. The design of \name prevent such leakage of input data from happening due to the following design choices:

\begin{enumerate}
	\item \emph{Device removal.} The primary usage model for our solution is one where the user attaches the \device device before a security-critical web operation and removes it after it. Thus, in such typical use, user input events outside the security-critical operation are not shared with the server. We do not recommend using our solution as a generic input protection mechanism for all web browsing, but rather as a hardening mechanism for only specific security-critical operations.

	\item \emph{Server white-listing.} The \device send the user input only to one (or more) pre-authorized (white-listed) servers. Therefore, even if the user would forget to remove the \device device from the host after the security-critical operation, the user input would be shared only with known and trusted servers. Such servers can implement additional privacy-preserving mechanisms like send a signal to the device to stop input sharing once the operation is completed.

	\item \emph{Safe handling of tabs.} As the \device uses \webusb as the communication channel through the host's browser, the implementation of the \webusb restricts only one website (known as the \emph{landing page}) to bind with the \usb device~\cite{webuseb_google}. This ensures that if the user switches the browser tab \emph{during the security-critical operation}, the keystrokes from that application will not be forwarded to the \device unless the user reinitializes the device manually.
\end{enumerate}

Finally, we emphasize that even in the worst case where the user forgets to remove the device and one of the white-listed servers turns out to be malicious, our solution does not \emph{reduce} the user's privacy when compared to use without our solution. Since we assume a compromised host, the OS can trivially share all user input with any server regardless of whether our solution is used or not.



\subsection{Other Security Considerations}

\myparagraph{Default values} \name eliminates any default values on the webpage. However, the host can always show default values to the user. If the user does not type the value by herself, the server rejects the input as the data from the browser and the trace does not match.

\myparagraph{Trace dropping} Since all communication from \device to the server is mediated by the untrusted host, the adversary may also attempt to manipulate the traces by selectively dropping packets (e.g., remove certain user input). However, such attacks are prevented by the use of a standard TLS connection.

\myparagraph{Cross-device attacks} An additional attack strategy is to trick the user to provide input for the configuration of one safety-critical device but use this user input for the configuration of another device. In such cross-device attacks, the host presents to the user the configuration user interface from server A but tricks \device to establish a connection with server B.

Cross-device attacks are only possible, if (\emph{i}) the same \device is pre-configured for both servers A and B, (\emph{ii}) every user input field in the configuration web pages of servers A and B is interchangeable, and (\emph{iii}) both configuration pages have exactly the same labels. We consider such cases rare. 
To protect against cross-device attacks, both configuration user interfaces A and B can be processed with the same instance of \tool which can annotate the pages with unique labels.




